{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tiwar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from gensim.models import Word2Vec\n",
    "from datasets import load_dataset\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\tiwar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First dataset item: {'text': 'Soon we dropped into a living forest, where cold-tolerant evergreens and boreal animals still evoke the Canadian heritage of an ecosystem pushed south by glaciers 20,000 years ago.'}\n",
      "Building Word2Vec vocabulary...\n",
      "Model trained and saved at: C:\\Users\\tiwar\\OneDrive - Amity University\\AIML\\AIcore\\word2vec.model\\my_word2vec.model\n"
     ]
    }
   ],
   "source": [
    "# Download NLTK tokenizer\n",
    "nltk.download(\"punkt\")\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"agentlans/high-quality-english-sentences\", split=\"train\")\n",
    "# Debug: Check dataset structure\n",
    "print(\"First dataset item:\", dataset[0])\n",
    "# Extract and preprocess sentences\n",
    "def preprocess_sentences(dataset):\n",
    "    sentences = []\n",
    "    for item in dataset:\n",
    "        sentence = item.get(\"text\", \"\").strip()  # Use \"text\" instead of \"sentence\"\n",
    "        if sentence:  # Ensure it's not empty\n",
    "            tokens = word_tokenize(sentence.lower())  # Tokenize and lowercase\n",
    "            sentences.append(tokens)\n",
    "    return sentences\n",
    "# Process sentences\n",
    "sentences = preprocess_sentences(dataset)\n",
    "# Ensure we have valid sentences\n",
    "if len(sentences) == 0:\n",
    "    raise ValueError(\"No valid sentences found. Check dataset structure.\")\n",
    "# Train Word2Vec model\n",
    "print(\"Building Word2Vec vocabulary...\")\n",
    "model = Word2Vec(sentences, vector_size=100, window=5, min_count=2, workers=4, sg=1, epochs=4)\n",
    "# Define model save path\n",
    "model_dir = r\"C:\\Users\\tiwar\\OneDrive - Amity University\\AIML\\AIcore\\word2vec.model\"\n",
    "os.makedirs(model_dir, exist_ok=True)  # Ensure directory exists\n",
    "model_path = os.path.join(model_dir, \"my_word2vec.model\")\n",
    "# Save the trained model\n",
    "model.save(model_path)\n",
    "print(f\"Model trained and saved at: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top similar words to 'monitor':\n",
      "[('monitors', 0.7954384684562683), ('monitoring', 0.7879633903503418), ('track', 0.75963294506073), ('assess', 0.7521328330039978), ('evaluate', 0.7421494722366333)]\n"
     ]
    }
   ],
   "source": [
    "# Load the trained Word2Vec model\n",
    "model = Word2Vec.load(r\"C:\\Users\\tiwar\\OneDrive - Amity University\\AIML\\AIcore\\word2vec.model\\my_word2vec.model\")\n",
    "# Test the model with a word similarity check\n",
    "word = \"monitor\"  # Replace with a word from your dataset\n",
    "if word in model.wv:\n",
    "    print(f\"Top similar words to '{word}':\")\n",
    "    print(model.wv.most_similar(word, topn=5))  # Show similar words\n",
    "else:\n",
    "    print(f\"'{word}' not found in vocabulary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 words similar to 'data':\n",
      "  information: 0.8236\n",
      "  datasets: 0.7703\n",
      "  database: 0.7556\n",
      "  anonymised: 0.7448\n",
      "  dataset: 0.7434\n",
      "Top 5 words similar to 'science':\n",
      "  sciences: 0.8335\n",
      "  mathematics: 0.8204\n",
      "  humanities: 0.8082\n",
      "  engineering: 0.8077\n",
      "  biology: 0.8061\n",
      "Top 5 words similar to 'ai':\n",
      "  robotics: 0.8010\n",
      "  bi: 0.7737\n",
      "  rpa: 0.7701\n",
      "  technology: 0.7632\n",
      "  ict: 0.7582\n",
      "Top 5 words similar to 'learning':\n",
      "  teaching: 0.8454\n",
      "  game-based: 0.8121\n",
      "  coaching: 0.7971\n",
      "  student-centered: 0.7928\n",
      "  self-directed: 0.7910\n",
      "Top 5 words similar to 'technology':\n",
      "  technologies: 0.8429\n",
      "  game-changing: 0.7941\n",
      "  exascale: 0.7905\n",
      "  robotics: 0.7892\n",
      "  nanotechnology: 0.7809\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "# Load the trained model\n",
    "model_path = r\"C:\\Users\\tiwar\\OneDrive - Amity University\\AIML\\AIcore\\word2vec.model\\my_word2vec.model\"\n",
    "model = Word2Vec.load(model_path)\n",
    "# Function to test similar words\n",
    "def test_word_similarity(word):\n",
    "    if word in model.wv.key_to_index:  # Corrected check\n",
    "        similar_words = model.wv.most_similar(word, topn=5)\n",
    "        print(f\"Top 5 words similar to '{word}':\")\n",
    "        for similar_word, similarity in similar_words:\n",
    "            print(f\"  {similar_word}: {similarity:.4f}\")\n",
    "    else:\n",
    "        print(f\"'{word}' not found in vocabulary.\")\n",
    "# Test words\n",
    "test_words = [\"data\", \"science\", \"ai\", \"learning\", \"technology\"]\n",
    "for word in test_words:\n",
    "    test_word_similarity(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cypher Logic\n",
    "def analogy(text, model):\n",
    "    words = word_tokenize(text)\n",
    "    encrypted_words = []\n",
    "    for word in words:\n",
    "        if word in model.wv:\n",
    "            similar_word = model.wv.most_similar(word, topn=1)[0][0]  # Get the closest word\n",
    "            encrypted_words.append(similar_word)\n",
    "        else:\n",
    "            encrypted_words.append(word)  # If not in vocab, keep the same\n",
    "    return ' '.join(encrypted_words)\n",
    "def original(encrypted_text, model):  # Ensure both parameters are included\n",
    "    words = word_tokenize(encrypted_text)\n",
    "    decrypted_words = []\n",
    "    for word in words:\n",
    "        if word in model.wv:\n",
    "            original_word = model.wv.most_similar(word, topn=1)[0][0]  # Find nearest neighbor back\n",
    "            decrypted_words.append(original_word)\n",
    "        else:\n",
    "            decrypted_words.append(word)  # Keep same if not found\n",
    "    \n",
    "    return ' '.join(decrypted_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analogy: seconds\n",
      "Original: minute\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# Load the trained Word2Vec model\n",
    "model = Word2Vec.load(r\"C:\\Users\\tiwar\\OneDrive - Amity University\\AIML\\AIcore\\word2vec.model\\my_word2vec.model\")\n",
    "text = \"minute\"\n",
    "encrypted = analogy(text, model)\n",
    "print(\"Analogy:\", encrypted)\n",
    "decrypted = original(encrypted, model)\n",
    "print(\"Original:\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184204\n"
     ]
    }
   ],
   "source": [
    "print(len(model.wv))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
